# from bs4 import BeautifulSoup
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait

import base64
import io
# from PIL import Image
from PIL import Image, ImageEnhance, ImageFilter
import matplotlib.pyplot as plt
import pytesseract
import pandas as pd
import cv2
import numpy as np

def get_image(driver):
    WebDriverWait(driver, 2).until(
            EC.presence_of_element_located((By.ID, "imgCaptcha"))  # ì˜ˆì•½ í˜ì´ì§€ì˜ íŠ¹ì • ìš”ì†Œ classë¡œ ë³€ê²½
        )
    img_element = driver.find_element(By.ID, "imgCaptcha")

    # ì´ë¯¸ì§€ src ì†ì„± ì¶”ì¶œ
    img_src = img_element.get_attribute("src")
    return img_src
    # print(f"ì´ë¯¸ì§€ src: {img_src}")

def pass_captcha(driver):
    img_src = get_image(driver)
    print(img_src)

    # Base64 ì´ë¯¸ì§€ ë¬¸ìì—´ (ì˜ˆ: data:image/jpeg;base64,... í˜•íƒœë¼ë©´ 'data:image/jpeg;base64,' ë¶€ë¶„ ì œê±°)
    base64_string = img_src #"ì—¬ê¸°ì—_ìº¡ì± _ì´ë¯¸ì§€_base64_ë¬¸ìì—´_ì „ì²´_ë¶™ì—¬ë„£ê¸°"

    # í•„ìš”ì‹œ ì ‘ë‘ì‚¬ ì œê±°
    if base64_string.startswith("data:image"):
        base64_string = base64_string.split(",")[1]

    # # 2. ë””ì½”ë”© ë° PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜
    # image_data = base64.b64decode(base64_string)
    # image = Image.open(io.BytesIO(image_data))

    # # 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (OCR ì„±ëŠ¥ í–¥ìƒìš©)
    # image = image.convert("L")  # í‘ë°± ë³€í™˜
    # image = image.resize((image.width * 2, image.height * 2))  # í•´ìƒë„ ì—…
    # image = image.filter(ImageFilter.SHARPEN)  # ì„ ëª…í•˜ê²Œ
    # image = ImageEnhance.Contrast(image).enhance(2.0)  # ëŒ€ë¹„ ì¦ê°€

    # 1. Base64 ë””ì½”ë”© ë° PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜
    image_data = base64.b64decode(base64_string)
    image = Image.open(io.BytesIO(image_data))

    # 2. PIL ì´ë¯¸ì§€ â†’ OpenCVë¡œ ë³€í™˜
    cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

    # # â–¶ ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ + Otsu ì„ê³„ê°’ + Morph Open)
    # blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    # _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    # kernel = np.ones((2, 2), np.uint8)
    # cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

    # 1. ë¸”ëŸ¬ë§
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # 2. ì´ì§„í™” (Otsu ë˜ëŠ” ì ì‘í˜•)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)

    # 3. ëª¨í´ë¡œì§€ ì—°ì‚°
    kernel = np.ones((3,3), np.uint8)
    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)

    # 4. ë¯¸ë””ì•ˆ ë¸”ëŸ¬
    denoised = cv2.medianBlur(closed, 3)

    # 5. ì‘ì€ ì—°ê²° ìš”ì†Œ ì œê±°
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(denoised, 8, cv2.CV_32S)
    min_size = 50  # ì´ ê°’ì€ ì´ë¯¸ì§€ì— ë”°ë¼ ì¡°ì • í•„ìš”
    result = np.zeros_like(denoised)
    for i in range(1, num_labels):
        if stats[i, cv2.CC_STAT_AREA] >= min_size:
            result[labels == i] = 255

    # 3. ë‹¤ì‹œ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    image = Image.fromarray(result)

    # 4. ì¶”ê°€ ì „ì²˜ë¦¬ (PIL ë°©ì‹)
    image = image.resize((image.width * 2, image.height * 2))  # í™•ëŒ€
    image = image.filter(ImageFilter.SHARPEN)  # ì„ ëª…í™”
    image = ImageEnhance.Contrast(image).enhance(2.0)  # ëŒ€ë¹„ ì¦ê°€

    # 5. OCR ì‹¤í–‰
    # text = pytesseract.image_to_string(image, lang='eng')  # í•„ìš” ì‹œ lang='kor+eng'


    # OCR ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    ocr_data = pytesseract.image_to_data(image, lang='eng', output_type=pytesseract.Output.DATAFRAME)

    # ìœ íš¨í•œ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§
    ocr_data = ocr_data[ocr_data.conf != -1]

    # ê²°ê³¼ ë³´ê¸°
    print(ocr_data[['text', 'left', 'top', 'width', 'height', 'conf']])
    # 4. OCR ì‹¤í–‰ (í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ lang='kor+eng' ë“±ìœ¼ë¡œ ì„¤ì •)
    # text = pytesseract.image_to_string(image, lang='eng')

    # print("ğŸ“Œ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", text.strip())

    plt.imshow(image, cmap='gray')
    plt.axis('off')
    # plt.title("ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€(OCR ëŒ€ìƒ)")
    plt.show()

